---
title: Installation
---

Kaito requires an existing Kubernetes cluster. This guide provides steps for common cloud providers, but the cluster can be hosted on any cloud provider.

## Prerequisites

Before you begin, ensure you have the following tools installed.

- [Helm](https://helm.sh) to install this operator
- [kubectl](https://kubernetes.io/docs/tasks/tools/) to view Kubernetes resources
- [git](https://git-scm.com/downloads) to clone this repo locally
- [yq](https://github.com/mikefarah/yq) to process yaml files
- [jq](https://jqlang.github.io/jq/download) to process JSON file

**Important Note**:
Ensure you use a release branch of the repository for a stable version of the installation.

For each provider, these are additional prerequisites:

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs groupId="provider">
<TabItem value="azure" label="Azure" default>

- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to provision Azure resources

</TabItem>
<TabItem value="aws" label="AWS" default>

- [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) to provision AWS resources
- [Eksctl](https://eksctl.io/installation/) (>= v0.191.0) to create and manage clusters on EKS
- 
</TabItem>
</Tabs>

## Create a Kubernetes cluster

Create a cluster using either the following cloud providers or bring your own existing Kubernetes cluster.

<Tabs groupId="provider">
<TabItem value="azure" label="Azure" default>

Run the following Azure CLI commands to create a cluster on Azure Kubernetes Service (AKS).

```bash
export RESOURCE_GROUP="kaito-rg"
export CLUSTER_NAME="kaito"
export LOCATION="eastus"
az group create --name $RESOURCE_GROUP --location $LOCATION
az aks create --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME --enable-oidc-issuer --enable-workload-identity --enable-managed-identity --generate-ssh-keys
```

Connect to the AKS cluster.

```bash
az aks get-credentials --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME
```

If you do not have `kubectl` installed locally, you can install using the following Azure CLI command.

```bash
az aks install-cli
```
</TabItem>
<TabItem value="aws" label="AWS" default>

If you do not already have a cluster on Elastic Kubernetes Service (EKS), run the following commands to create one:

```bash
cd ../.. #go back to main directory to use MAKE commands

export AWS_CLUSTER_NAME=kaito-aws
export AWS_REGION=us-west-2
export AWS_PARTITION=aws
export AWS_K8S_VERSION=1.30
export KARPENTER_NAMESPACE=kube-system
export AWS_ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"

make deploy-aws-cloudformation
make create-eks-cluster
```

If you already have an EKS cluster, connect to it using
```bash
aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_REGION
```

</TabItem>
</Tabs>

## Install Kaito

<Tabs groupId="provider">
<TabItem value="azure" label="Azure" default>

#### Install workspace controller

:::tip

Be sure you've cloned this repo and connected to your AKS cluster before attempting to install the Helm charts.

:::

Install the Workspace controller.

```bash
make az-patch-install-helm
```

Note that if you have installed another node provisioning controller that supports Karpenter-core APIs, the following steps for installing `gpu-provisioner` can be skipped.

#### Install gpu-provisioner controller

The *gpu-provisioner* controller requires the [workload identity](https://learn.microsoft.com/azure/aks/workload-identity-overview?tabs=dotnet) feature to acquire the access token to the AKS cluster.

:::tip

Run the following commands only if your AKS cluster does not already have the Workload Identity and OIDC issuer features enabled.

:::

```bash
az aks update -g $RESOURCE_GROUP -n $CLUSTER_NAME --enable-oidc-issuer --enable-workload-identity --enable-managed-identity
```

Run the following command to create a managed identity for the *gpu-provisioner* controller and federated identity credential. The identity is assigned the *Contributor* role for the managed cluster resource to allow changing `$CLUSTER_NAME` (e.g., provisioning new nodes in it).

```bash
make prepare-kaito-addon-identity
```

```bash
make gpu-provisioner-helm
```

</TabItem>
<TabItem value="aws" label="AWS" default>

Install the Karpenter controller.
```bash
make aws-karpenter-helm
```

Install the workspace controller.
```bash
make aws-patch-install-helm
```

</TabItem>
</Tabs>

## Verify installation
You can run the following commands to verify the installation of the controllers were successful.

Check status of the Helm chart installations.

```bash
helm list -n kaito-workspace
helm list -n gpu-provisioner
```

Check status of the `workspace`.

```bash
kubectl describe deploy kaito-workspace -n kaito-workspace
```

<Tabs groupId="provider">
<TabItem value="azure" label="Azure" default>

Check status of the `gpu-provisioner`.

```bash
kubectl describe deploy gpu-provisioner -n gpu-provisioner
```

If you see that the `gpu-provisioner` deployment is not running after some time, it's possible that some values incorrect in your `gpu-provisioner-values.yaml`.

Run the following command to check `gpu-provisioner` pod logs for additional details.

```bash
kubectl logs --selector=app.kubernetes.io\/name=gpu-provisioner -n gpu-provisioner
```

</TabItem>
<TabItem value="aws" label="AWS" default>

Check status of `karpenter`.

```bash
kubectl describe deploy karpenter -n $KARPENTER_NAMESPACE
```

</TabItem>
</Tabs>


## Clean up


<Tabs groupId="provider">
<TabItem value="azure" label="Azure" default>

```bash
helm uninstall gpu-provisioner -n gpu-provisioner
helm uninstall kaito-workspace -n kaito-workspace
```

</TabItem>
<TabItem value="aws" label="AWS" default>

```bash
helm uninstall karpenter -n karpenter
helm uninstall kaito-workspace -n kaito-workspace
```

</TabItem>
</Tabs>


